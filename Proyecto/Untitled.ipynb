{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7758658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program files\\python39\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-14.0.2-cp311-cp311-win_amd64.whl (24.6 MB)\n",
      "Collecting pyarrow-hotfix\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Requirement already satisfied: pandas in d:\\program files\\python39\\lib\\site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\program files\\python39\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\program files\\python39\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.9.1-cp311-cp311-win_amd64.whl (364 kB)\n",
      "Collecting huggingface-hub>=0.18.0\n",
      "  Using cached huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "Requirement already satisfied: packaging in d:\\program files\\python39\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program files\\python39\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\program files\\python39\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\program files\\python39\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program files\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program files\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python39\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python39\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, filelock, dill, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 datasets-2.15.0 dill-0.3.7 filelock-3.13.1 frozenlist-1.4.1 fsspec-2023.10.0 huggingface-hub-0.20.1 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.2 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: D:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dcf22f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Python39\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b1e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")\n",
    "\n",
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccdf48a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nThe Legislature finds and declares all of the following:\\n(a) Local educational agencies (LEA) must have an approved provider participant agreement with the State Department of Health Care Services through the federal Centers for Medicare and Medicaid Services to be eligible to provide services. To participate in the LEA Medi-Cal billing option program, LEAs must reinvest the federal reimbursement they receive under this program in health and social services for children and families, and develop and maintain a collaborative committee to assist them in decisions regarding the reinvestment of federal reimbursements. The providers and supervisors of staff for the assessment and medically necessary health services are those qualified medical practitioners the LEA employs or contracts with to render certain health services.\\n(b) The LEA billing option facilitates reinvestment in health and social services for students and their families so that schools can foster access to and provide comprehensive health services to eligible Medi-Cal students.\\n(c) The funds are reimbursement for olled on or after January 1, 1993, to provide services pursuant to this section may bill for those services provided on or after January 1, 1993.\\n(c) Nothing in this section shall be interpreted to expand the current category of professional health care practitioners permitted to directly bill the Medi-Cal program.\\n(d) Nothing in this section is intended to increase the scope of practice of any health professional providing services under this section or Medi-Cal requirements for physician prescription, order, and supervision.\\n(e) (1) For the purposes of this section, the local educational agency, as a condition of enrollment to provide services under this section, shall be considered the provider of services. A local educational agency provider, as a condition of enrollment to provide services under this section, shall enter into, and maintain, a contract with the department in accordance with guidelines contained in regulations adopted by the director and published in Title 22 of the California Code of Regulations.\\n(2) Notwithstanding paragraph (1), a local educational agency providing services pursuant to this section shall utilize current safety net and traditional health care providers, when those providers are accessible to specific schoolsites identified by the local educational agency to participate in this program, rather than adding duplicate capacity.\\n(f) For the purposes of this section, covered services may include all of the following local educational agency services:\\n(1) Health and mental health evaluations and health and mental health education.\\n(2) Medical transportation.\\n(A) The following provisions shall not apply to medical transportation eligible to be billed under this section:\\n(i) Section 51323(a)(2)(A) of Title 22 of the California Code of Regulations.\\n(ii) Section 51323(a)(3)(B) of Title 22 of the California Code of Regulations.\\n(iii) For students whose medical or physical condition does not require the use of a gurney, Section 51231.1(f) of Title 22 of the California Code of Regulations.\\n(iv) For students whose medical or physical condition does not require the use of a wheelchair, Section 51231.2(e) of Title 22 of the California Code of Regulations.\\n(B) (i) Subparagraph (A) shall become inoperative on January 1, 2018, or on the date the director executes a declaration stating that the regulations implementing subparagraph (A) and Section 14118.5 have been updated, whichever is later.\\n(ii) The department shall post the declaration executed under clause (i) on its Internet Web site and transmit a copy of the declaration to the Assembly Committee on Budget and the Senate Committee on Budget and Fiscal Review and the LEA Ad Hoc Workgroup.\\n(iii) If subparagraph (A) becomes inoperative on January 1, 2018, subparagraph (A) and this subparagraph shall be inoperative on January 1, 2018, unless a later enacted statute enacted before that date, deletes or extends that date.\\n(iv) If subparagraph (A) becomes inoperative on the date the director executes a declaration as described in clause (i), subparagraph (A) and this subparagraph shall be inoperative on the January 1 immediately following the date subparagraph (A) becomes inoperative, unless a later enacted statute enacted before that date, deletes or extends that date.\\n(3) Nursing services.\\n(4) Occupational therapy.\\n(5) Physical therapy.\\n(6) Physician services.\\n(7) Mental health and counseling services.\\n(8) School health aide services.\\n(9) Speech pathology services. These services may be provided by either of the following:\\n(A) A licensed speech pathologist.\\n(B) A credentialed speech-language pathologist, to the extent authorized by Chapter 5.3 (commencing with Section 2530) of Division 2 of the Business and Professions Code.\\n(10) Audiology services.\\n(11) Targeted case management services for children regardless of whether the child has an individualized education plan (IEP) or an individualized family service plan (IFSP).\\n(g) Local educational agencies may, but need not, provide any or all of the services specified in subdivision (f).\\n(h) For the purposes of this section, “local educational agency” means the governing body of any school district or community college district, the county office of education, a charter school, a state special school, a California State University campus, or a University of California campus.\\n(i) Notwithstanding any other law, a community college district, a California State University campus, or a University of California campus, consistent with the requirements of this section, may bill for services provided to any student, regardless of age, who is a Medi-Cal recipient.\\n(j) No later than July 1, 2013, and every year thereafter, the department shall make publicly accessible an annual accounting of all funds collected by the department from federal Medicaid payments allocable to local educational agencies, including, but not limited to, the funds withheld pursuant to subdivision (g) of Section 14115.8. The accounting shall detail amounts withheld from federal Medicaid payments to each participating local educational agency for that year. One-time costs for the development of this accounting shall not exceed two hundred fifty thousand dollars ($250,000).\\n(k) (1) If the requirements in paragraphs (2) and (4) are satisfied, the department shall seek federal financial participation for covered services that are provided by a local educational agency pursuant to subdivision (a) to a child who is an eligible Medi-Cal beneficiary, regardless of either of the following:\\n(A) Whether the child has an IEP or an IFSP.\\n(B) Whether those same services are provided at no charge to the beneficiary or to the community at large.\\n(2) The local educational agency shall take all reasonable measures to ascertain and pursue claims for payment of covered services specified in this section against legally liable third parties pursuant to Section 1902(a)(25) of the federal Social Security Act (42 U.S.C. Sec. 1396a(a)(25)).\\n(3) If a legally liable third party receives a claim submitted by a local educational agency pursuant to paragraph (2), the legally liable third party shall either reimburse the claim or issue a notice of denial of noncoverage of services or benefits. If there is no response to a claim submitted to a legally liable third party by a local educational agency within 45 days, the local educational agency may bill the Medi-Cal program pursuant to subdivision (b). The local educational agency shall retain a copy of the claim submitted to the legally liable third party for a period of three years.\\n(4) This subdivision shall not be implemented until the department obtains any necessary federal approvals.',\n",
       " 'summary': 'Existing law provides for the Medi-Cal program, which is administered by the State Department of Health Care Services, under which qualified low-income persons receive health care benefits. The Medi-Cal program is, in part, governed and funded by federal Medicaid program provisions. Existing law provides that specified services, including targeted case management services for children with an individualized education plan (IEP) or an individualized family service plan (IFSP), provided by local educational agencies (LEAs) are covered Medi-Cal benefits, and authorizes an LEA to bill for those services. Existing law requires the department to perform various activities with respect to the billing option for services provided by LEAs. Existing law defines an LEA as the governing body of any school district or community college district, the county office of education, a state special school, a California State University campus, or a University of California campus.\\nThis bill would require the department to seek federal financial participation for covered services that are provided by an LEA to a child who is an eligible Medi-Cal beneficiary regardless of whether the child has an IEP or an IFSP, or whether those same services are provided at no charge to the beneficiary or to the community at large, if the LEA takes all reasonable measures to ascertain and pursue claims for payment of covered services against legally liable 3rd parties. The bill would require a legally liable 3rd party to either reimburse the claim or issue a notice of denial of noncoverage of services or benefits if the legally liable 3rd party receives a claim for payment of covered services submitted by an LEA. The bill would authorize an LEA to bill the Medi-Cal program if there is no response to a claim for payment of covered services submitted to a legally liable 3rd party within 45 days, and would require the LEA to retain a copy of the claim submitted to the legally liable 3rd party for a period of 3 years. The bill would expand the definition of an LEA to include the governing body of a charter school. The bill would provide that these provisions shall not be implemented until the department obtains necessary federal approvals.\\nThis bill would also expand the authority of an LEA to provide targeted case management services.',\n",
       " 'title': 'An act to amend Section 14132.06 of the Welfare and Institutions Code, relating to Medi-Cal.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b29428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████| 2.32k/2.32k [00:00<?, ?B/s]\n",
      "spiece.model: 100%|██████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 828kB/s]\n",
      "tokenizer.json: 100%|█████████████████████████████████████████████████████████████| 1.39M/1.39M [00:00<00:00, 1.90MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b87454bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396e193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████| 989/989 [00:03<00:00, 281.44 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 281.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486f2a6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorForSeq2Seq\n\u001b[1;32m----> 3\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d22935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288f04d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████| 1.49k/1.49k [00:00<00:00, 1.50MB/s]\n",
      "model.safetensors: 100%|████████████████████████████████████████████████████████████| 242M/242M [02:24<00:00, 1.68MB/s]\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████| 2.32k/2.32k [00:00<00:00, 2.33MB/s]\n",
      "spiece.model: 100%|██████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 924kB/s]\n",
      "tokenizer.json: 100%|█████████████████████████████████████████████████████████████| 2.42M/2.42M [00:01<00:00, 2.11MB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████████| 2.20k/2.20k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c93cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"La verdad ella no explica mucho, todo va hacia los estudiantes quiénes buscan la información para exponerla ese mismo día o a la siguiente clase. Ubica a todos los que entran así que si faltas no esperes que al final te pasé solo porque si. Algo aburrida y quita tiempo la materia pero 10 seguro.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811f9211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 230, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Ubica a todos los estudiantes quiénes buscan la información para exponerla ese mismo da o a la siguiente clase. Algo aburrida y quita tiempo la materia pero 10 seguro.'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(ARTICLE, max_length=230, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b42b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = \"Sabe enseñar, cubre bien los temas, es una persona muy linda y le gusta que participen. Deja de 1 a 3 tareas por semana, deja un proyecto por equipo que se expone al final del semestre, en línea no aplicó examen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7fbc235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 230, but your input_length is only 90. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Deja de 1 a 3 tareas por semana, deja un proyecto por equipo que se expone al final del semestre, en lnea no aplicó examen .'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(a2, max_length=230, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458fcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = \"Uno de los aspectos fundamentales de la IA es el aprendizaje automático, que permite a las máquinas mejorar su rendimiento a medida que se enfrentan a nuevas situaciones y datos. El aprendizaje profundo, una rama específica del aprendizaje automático, utiliza redes neuronales artificiales para simular el procesamiento de información del cerebro humano. Esto ha llevado a avances significativos en áreas como el reconocimiento de patrones, la visión por computadora y el procesamiento del lenguaje natural. La IA se implementa en una variedad de aplicaciones cotidianas, como motores de búsqueda en internet, asistentes virtuales, recomendaciones personalizadas en plataformas de transmisión de contenido y sistemas de reconocimiento facial. Estos avances tecnológicos han transformado la forma en que interactuamos con la tecnología y entre nosotros, creando un impacto profundo en la sociedad y la economía.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f49ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'El aprendizaje profundo utiliza redes neuronales artificiales para simular el procesamiento de información del cerebro humano . La IA se implementa en una variedad de aplicaciones cotidianas, como motores de bsqueda, asistentes virtuales recomendaciones personalizadas en plataformas de transmisión de contenido y'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(a3, max_length=230, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2461e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████████████| 1.58k/1.58k [00:00<?, ?B/s]\n",
      "D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 1625.22 MB. The target location C:\\Users\\ricar\\.cache\\huggingface\\hub only has 1473.69 MB free disk space.\n",
      "  warnings.warn(\n",
      "D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 1625.22 MB. The target location C:\\Users\\ricar\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn\\blobs only has 1473.69 MB free disk space.\n",
      "  warnings.warn(\n",
      "model.safetensors:  20%|███████████▊                                               | 325M/1.63G [02:07<08:28, 2.55MB/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model facebook/bart-large-cnn with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_tf_bart.TFBartForConditionalGeneration'>). See the original errors:\n\nwhile loading with TFAutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2785, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 389, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1457, in hf_hub_download\n    http_get(\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 552, in http_get\n    raise EnvironmentError(\nOSError: Consistency check failed: file should be of size 1625222120 but has size 325405728 (model.safetensors).\nWe are sorry for the inconvenience. Please retry download and pass `force_download=True, resume_download=False` as argument.\nIf the issue persists, please let us know by opening an issue on https://github.com/huggingface/huggingface_hub.\n\nwhile loading with TFBartForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connection.py\", line 174, in _new_conn\n    conn = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 72, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\socket.py\", line 962, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n    httplib_response = self._make_request(\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n    conn.connect()\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connection.py\", line 363, in connect\n    self.sock = conn = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connection.py\", line 186, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x00000224D41CA250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 798, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /facebook/bart-large-cnn/resolve/main/model.safetensors.index.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000224D41CA250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2818, in from_pretrained\n    if has_file(pretrained_model_name_or_path, SAFE_WEIGHTS_INDEX_NAME, **has_file_kwargs):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 618, in has_file\n    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n    return request(\"head\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /facebook/bart-large-cnn/resolve/main/model.safetensors.index.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000224D41CA250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarizer2 \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-large-cnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 870\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    881\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mD:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\pipelines\\base.py:282\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    281\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m         )\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model facebook/bart-large-cnn with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_tf_bart.TFBartForConditionalGeneration'>). See the original errors:\n\nwhile loading with TFAutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2785, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 389, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1457, in hf_hub_download\n    http_get(\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 552, in http_get\n    raise EnvironmentError(\nOSError: Consistency check failed: file should be of size 1625222120 but has size 325405728 (model.safetensors).\nWe are sorry for the inconvenience. Please retry download and pass `force_download=True, resume_download=False` as argument.\nIf the issue persists, please let us know by opening an issue on https://github.com/huggingface/huggingface_hub.\n\nwhile loading with TFBartForConditionalGeneration, an error is thrown:\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connection.py\", line 174, in _new_conn\n    conn = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 72, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\socket.py\", line 962, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n    httplib_response = self._make_request(\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n    conn.connect()\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connection.py\", line 363, in connect\n    self.sock = conn = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connection.py\", line 186, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x00000224D41CA250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 798, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /facebook/bart-large-cnn/resolve/main/model.safetensors.index.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000224D41CA250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2818, in from_pretrained\n    if has_file(pretrained_model_name_or_path, SAFE_WEIGHTS_INDEX_NAME, **has_file_kwargs):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 618, in has_file\n    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n    return request(\"head\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\Program Files\\Python39\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /facebook/bart-large-cnn/resolve/main/model.safetensors.index.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000224D41CA250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n\n\n"
     ]
    }
   ],
   "source": [
    "summarizer2 = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2a78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
