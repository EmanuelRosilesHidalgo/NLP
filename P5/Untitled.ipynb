{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7508a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.calibration import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, make_scorer, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa6207",
   "metadata": {},
   "source": [
    "<h1>Cross Validate</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d1d0c",
   "metadata": {},
   "source": [
    "<h2>LR - Frequency</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f67f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.44572551 0.46789743 0.47366973 0.47588564 0.48445446]\n",
      "F1-score Promedio: 0.46952655719986014\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador\n",
    "clf_polarity = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f645c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.44572551 0.46789743 0.47366973 0.47588564 0.48445446]\n",
      "\n",
      "Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     clase_1       0.44      0.30      0.36        77\n",
      "     clase_2       0.29      0.22      0.25       105\n",
      "     clase_3       0.37      0.38      0.37       326\n",
      "     clase_4       0.43      0.36      0.39       988\n",
      "     clase_5       0.83      0.88      0.86      3338\n",
      "\n",
      "    accuracy                           0.72      4834\n",
      "   macro avg       0.47      0.43      0.45      4834\n",
      "weighted avg       0.70      0.72      0.71      4834\n",
      "\n",
      "\n",
      "Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     clase_1       0.48      0.33      0.39        99\n",
      "     clase_2       0.30      0.27      0.28       116\n",
      "     clase_3       0.42      0.37      0.39       353\n",
      "     clase_4       0.45      0.37      0.41       947\n",
      "     clase_5       0.83      0.90      0.87      3319\n",
      "\n",
      "    accuracy                           0.73      4834\n",
      "   macro avg       0.50      0.45      0.47      4834\n",
      "weighted avg       0.71      0.73      0.72      4834\n",
      "\n",
      "\n",
      "Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     clase_1       0.54      0.42      0.47        89\n",
      "     clase_2       0.31      0.23      0.26       114\n",
      "     clase_3       0.43      0.35      0.38       364\n",
      "     clase_4       0.43      0.36      0.39       935\n",
      "     clase_5       0.82      0.89      0.86      3332\n",
      "\n",
      "    accuracy                           0.72      4834\n",
      "   macro avg       0.51      0.45      0.47      4834\n",
      "weighted avg       0.70      0.72      0.71      4834\n",
      "\n",
      "\n",
      "Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     clase_1       0.52      0.41      0.46        87\n",
      "     clase_2       0.31      0.25      0.28       129\n",
      "     clase_3       0.41      0.36      0.39       333\n",
      "     clase_4       0.42      0.36      0.39       903\n",
      "     clase_5       0.84      0.89      0.87      3382\n",
      "\n",
      "    accuracy                           0.73      4834\n",
      "   macro avg       0.50      0.46      0.48      4834\n",
      "weighted avg       0.71      0.73      0.72      4834\n",
      "\n",
      "\n",
      "Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     clase_1       0.53      0.43      0.48        91\n",
      "     clase_2       0.40      0.28      0.33       121\n",
      "     clase_3       0.38      0.34      0.36       323\n",
      "     clase_4       0.43      0.38      0.40       942\n",
      "     clase_5       0.84      0.89      0.86      3356\n",
      "\n",
      "    accuracy                           0.73      4833\n",
      "   macro avg       0.51      0.46      0.48      4833\n",
      "weighted avg       0.71      0.73      0.72      4833\n",
      "\n",
      "F1-score Promedio: 0.46952655719986014\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador\n",
    "clf_polarity = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Definir target_names\n",
    "target_names = ['clase_1', 'clase_2', 'clase_3', 'clase_4', 'clase_5']  # Reemplaza con las clases reales\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las predicciones y puntuaciones\n",
    "y_pred_cv = cross_val_predict(clf_polarity, X_train_final, y_train, cv=kf)\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "\n",
    "# Imprimir el informe de clasificación para cada fold\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train_final)):\n",
    "    X_train_fold, X_test_fold = X_train_final[train_index], X_train_final[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    clf_polarity.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = clf_polarity.predict(X_test_fold)\n",
    "    \n",
    "    print(f\"\\nFold {i + 1}\")\n",
    "    print(classification_report(y_test_fold, y_pred_fold, target_names=target_names))\n",
    "\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe5a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.45596859 0.44256214 0.46658067 0.46126232 0.48275254]\n",
      "F1-score Promedio: 0.46182525389098145\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer(binary=True)\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador\n",
    "clf_polarity = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9b382",
   "metadata": {},
   "source": [
    "<h3>FINAL-MEJOR RESULTADO (Logistic Regression) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfd35df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "[[  54   16   14    8   12]\n",
      " [  21   37   43   23   21]\n",
      " [  18   34  170  111   89]\n",
      " [   6   16  101  430  610]\n",
      " [   0    4   48  411 3746]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.52      0.53       104\n",
      "           2       0.35      0.26      0.29       145\n",
      "           3       0.45      0.40      0.43       422\n",
      "           4       0.44      0.37      0.40      1163\n",
      "           5       0.84      0.89      0.86      4209\n",
      "\n",
      "    accuracy                           0.73      6043\n",
      "   macro avg       0.52      0.49      0.50      6043\n",
      "weighted avg       0.72      0.73      0.72      6043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer()\n",
    "\n",
    "X_train_vect = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vect = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train = hstack([X_train_vect, X_train[numeric_features].values])\n",
    "X_test = hstack([X_test_vect, X_test[numeric_features].values])\n",
    "\n",
    "clf_lr = LogisticRegression(max_iter=10000)\n",
    "clf_lr.fit(X_train, y_train)\n",
    " \n",
    "y_pred = clf_lr.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(conf_matrix)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f4c6f",
   "metadata": {},
   "source": [
    "<h2>SVM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fd15dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.36415662 0.37049847 0.36301339 0.34511615 0.37495746]\n",
      "F1-score Promedio: 0.3635484186741677\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer(binary=True)\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador SVM\n",
    "clf_polarity = SVC()\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec4ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer(binary=True)\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador SVM\n",
    "clf_polarity = SVC(kernel='linear')\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a60dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = CountVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador SVM\n",
    "clf_polarity = SVC(kernel='linear')\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fc2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.43765601 0.45100845 0.45128141 0.449842   0.47543115]\n",
      "F1-score Promedio: 0.45304380522340065\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = TfidfVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador SVM\n",
    "clf_polarity = SVC(kernel='linear')\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10cd76",
   "metadata": {},
   "source": [
    "<h2>MLP</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbec3845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.42233242 0.45010531 0.45362425 0.44193233 0.45075667]\n",
      "F1-score Promedio: 0.44375019398667853\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = TfidfVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador \n",
    "clf_polarity = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=200)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dc0230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.42648638 0.46602788 0.43019199 0.4485405  0.46325729]\n",
      "F1-score Promedio: 0.4469008060696386\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = TfidfVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador \n",
    "clf_polarity = MLPClassifier(hidden_layer_sizes=(50, 100), max_iter=400)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68572006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.44340992 0.46363151 0.46515402 0.45158974 0.45462694]\n",
      "F1-score Promedio: 0.45568242622315625\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = TfidfVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador \n",
    "clf_polarity = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=100)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195a0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n",
      "Puntuaciones de Validación Cruzada (F1-score): [0.40905099 0.45709282 0.45415696 0.45537018 0.47083514]\n",
      "F1-score Promedio: 0.44930121691619307\n"
     ]
    }
   ],
   "source": [
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')\n",
    "\n",
    "# Vectorización de texto\n",
    "vectorizer_title_opinion = TfidfVectorizer()\n",
    "X_train_vectorizer = vectorizer_title_opinion.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_title_opinion.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador \n",
    "clf_polarity = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_polarity, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
