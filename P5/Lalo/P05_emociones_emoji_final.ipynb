{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.calibration import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, make_scorer, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de X_train: 24169 documentos\n",
      "Tamaño de X_test: 6043 documentos\n",
      "Tamaño de y_train: 24169 etiquetas\n",
      "Tamaño de y_test: 6043 etiquetas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_frecuencia = CountVectorizer()\n",
    "vectorizer_binary = CountVectorizer(binary = True)\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "df_normalizacion = pd.read_pickle('df_tokenizacion_lematizacion_emojis_final.pkl')\n",
    "\n",
    "features = ['Title_Opinion', 'acumuladopositivo', 'acumuladonegative']\n",
    "numeric_features = ['acumuladopositivo', 'acumuladonegative']\n",
    "\n",
    "X = df_normalizacion[features]\n",
    "y = df_normalizacion['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'\\nTamaño de X_train: {len(X_train)} documentos')\n",
    "print(f'Tamaño de X_test: {len(X_test)} documentos')\n",
    "print(f'Tamaño de y_train: {len(y_train)} etiquetas')\n",
    "print(f'Tamaño de y_test: {len(y_test)} etiquetas\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.44677243 0.46789743 0.47388115 0.47588564 0.48445446]\n",
      "F1-score Promedio: 0.46977822199434965\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de texto\n",
    "X_train_vectorizer = vectorizer_frecuencia.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_frecuencia.transform(X_test['Title_Opinion'])\n",
    "\n",
    "# Combinar características numéricas y vectorizadas\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "# Inicializar el clasificador\n",
    "clf_lr = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# Inicializar KFold con el número deseado de divisiones (folds)\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "# Definir la métrica F1-score para la validación cruzada\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Aplicar la validación cruzada y obtener las puntuaciones\n",
    "cv_scores = cross_val_score(clf_lr, X_train_final, y_train, cv = kf, scoring = scoring_metric)\n",
    "\n",
    "# Imprimir las puntuaciones de validación cruzada\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "\n",
    "# Imprimir la puntuación media y la desviación estándar de las puntuaciones\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.45596859 0.44256214 0.46658067 0.46126232 0.48275254]\n",
      "F1-score Promedio: 0.46182525389098145\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_binary.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_binary.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_lr = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_lr, X_train_final, y_train, cv = kf, scoring = scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.40677536 0.42195651 0.4200832  0.42921319 0.44136328]\n",
      "F1-score Promedio: 0.4238783087485397\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_tfidf.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_tfidf.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_lr = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_lr, X_train_final, y_train, cv = kf, scoring = scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.29656362 0.27510307 0.28622718 0.27422927 0.27897558]\n",
      "F1-score Promedio: 0.2822197447429898\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_frecuencia.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_frecuencia.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_svm = SVC()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_svm, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.36415662 0.37049847 0.36301339 0.34511615 0.37495746]\n",
      "F1-score Promedio: 0.3635484186741677\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_binary.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_binary.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_svm = SVC()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_svm, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.21747358 0.21229895 0.22071545 0.22908578 0.23143698]\n",
      "F1-score Promedio: 0.22220214773023567\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_tfidf.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_tfidf.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_svm = SVC()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_svm, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.45366304 0.47440909 0.46528245 0.4546367  0.47666915]\n",
      "F1-score Promedio: 0.46493208848814715\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_frecuencia.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_frecuencia.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_mlp, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.4496908  0.45670306 0.46326104 0.44265294 0.47412617]\n",
      "F1-score Promedio: 0.45728680214562933\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_frecuencia.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_frecuencia.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_mlp, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.44646816 0.48283483 0.44852098 0.44830692 0.4701955 ]\n",
      "F1-score Promedio: 0.45926527698734654\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_frecuencia.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_frecuencia.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=500)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_mlp, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.44075526 0.44182548 0.44855088 0.45364299 0.46997477]\n",
      "F1-score Promedio: 0.45094987649351975\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_binary.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_binary.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_mlp, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de Validación Cruzada (F1-score): [0.40964617 0.44088708 0.46218743 0.4434351  0.45954357]\n",
      "F1-score Promedio: 0.44313987151099904\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_tfidf.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_tfidf.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=200)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "scoring_metric = make_scorer(f1_score, average='macro')\n",
    "\n",
    "cv_scores = cross_val_score(clf_mlp, X_train_final, y_train, cv=kf, scoring=scoring_metric)\n",
    "\n",
    "print(\"Puntuaciones de Validación Cruzada (F1-score):\", cv_scores)\n",
    "print(\"F1-score Promedio:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  54   16   14    8   12]\n",
      " [  21   37   43   23   21]\n",
      " [  18   34  170  111   89]\n",
      " [   6   16  101  430  610]\n",
      " [   0    4   48  411 3746]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.52      0.53       104\n",
      "           2       0.35      0.26      0.29       145\n",
      "           3       0.45      0.40      0.43       422\n",
      "           4       0.44      0.37      0.40      1163\n",
      "           5       0.84      0.89      0.86      4209\n",
      "\n",
      "    accuracy                           0.73      6043\n",
      "   macro avg       0.52      0.49      0.50      6043\n",
      "weighted avg       0.72      0.73      0.72      6043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorizer = vectorizer_frecuencia.fit_transform(X_train['Title_Opinion'])\n",
    "X_test_vectorizer = vectorizer_frecuencia.transform(X_test['Title_Opinion'])\n",
    "\n",
    "X_train_final = hstack([X_train_vectorizer, csr_matrix(X_train[numeric_features].values)])\n",
    "X_test_final = hstack([X_test_vectorizer, csr_matrix(X_test[numeric_features].values)])\n",
    "\n",
    "clf_lr = LogisticRegression(max_iter=10000)\n",
    "clf_lr.fit(X_train_final, y_train)\n",
    " \n",
    "y_pred = clf_lr.predict(X_test_final)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(conf_matrix)\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
